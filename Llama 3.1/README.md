# ğŸ¦™ MÃ³dulo 2: IntroducciÃ³n a Llama 3.1

## ğŸ“‹ DescripciÃ³n

Este mÃ³dulo proporciona una **demostraciÃ³n prÃ¡ctica completa** de las capacidades y caracterÃ­sticas de **Llama 3.1**, uno de los modelos de lenguaje mÃ¡s avanzados de Meta. A travÃ©s de un laboratorio interactivo, explorarÃ¡s todas las funcionalidades del modelo desde la carga hasta aplicaciones prÃ¡cticas.

## ğŸ“ Contenido del MÃ³dulo

```
codigo/modulo2/
â”œâ”€â”€ README.md                        # Este archivo
â””â”€â”€ laboratorio-modulo-n2.ipynb     # Laboratorio completo de Llama 3.1
```

## ğŸ¯ Objetivos de Aprendizaje

Al completar este mÃ³dulo, dominarÃ¡s:

1. **ğŸ”§ Carga y configuraciÃ³n** de modelos Llama 3.1
2. **âš¡ OptimizaciÃ³n de memoria** con cuantizaciÃ³n 4-bit
3. **ğŸ’¬ Capacidades conversacionales** y formato de chat
4. **ğŸŒ Soporte multilingÃ¼e** en 6+ idiomas
5. **ğŸ’» GeneraciÃ³n de cÃ³digo** en mÃºltiples lenguajes
6. **ğŸ“Š AnÃ¡lisis de rendimiento** y mÃ©tricas
7. **âš™ï¸ Configuraciones de generaciÃ³n** para diferentes casos de uso

## ğŸ““ Laboratorio Interactivo: `laboratorio-modulo-n2.ipynb`

### **ğŸš€ CaracterÃ­sticas Principales:**

- ğŸ® **DemostraciÃ³n completa** con 11 secciones estructuradas
- ğŸ”§ **Carga automÃ¡tica** con fallback a modelos alternativos
- ğŸ“Š **AnÃ¡lisis de rendimiento** en tiempo real
- ğŸŒ **Pruebas multilingÃ¼es** extensivas
- ğŸ’» **GeneraciÃ³n de cÃ³digo** especializada
- âš™ï¸ **ComparaciÃ³n de configuraciones** de generaciÃ³n

### **ğŸ“š Secciones del Laboratorio:**

#### **1. ğŸ”§ ConfiguraciÃ³n Inicial**
- ImportaciÃ³n de librerÃ­as necesarias
- ConfiguraciÃ³n de autenticaciÃ³n HuggingFace
- DetecciÃ³n automÃ¡tica de GPU/CPU

#### **2. ğŸ¦™ Clase Llama31Demo**
- Arquitectura modular para demostraciones
- GestiÃ³n de memoria y recursos
- InformaciÃ³n detallada del modelo

#### **3. âš¡ Carga con CuantizaciÃ³n**
- ConfiguraciÃ³n BitsAndBytesConfig 4-bit
- OptimizaciÃ³n de memoria RAM/VRAM
- ReducciÃ³n significativa de recursos

#### **4. ğŸ“¥ Carga BÃ¡sica (Fallback)**
- ConfiguraciÃ³n estÃ¡ndar sin cuantizaciÃ³n
- Modelo alternativo si Llama 3.1 no estÃ¡ disponible
- Manejo robusto de errores

#### **5. ğŸ’¬ Capacidades Conversacionales**
- Formato de chat con system/user/assistant
- AplicaciÃ³n de chat templates
- Conversaciones multi-turno

#### **6. ğŸŒ Capacidades MultilingÃ¼es**
- Pruebas en 6 idiomas: EspaÃ±ol, English, FranÃ§ais, Deutsch, Italiano, PortuguÃªs
- EvaluaciÃ³n de calidad por idioma
- ComparaciÃ³n de rendimiento

#### **7. ğŸ’» GeneraciÃ³n de CÃ³digo**
- Python, JavaScript, SQL
- Algoritmos y estructuras de datos
- AnÃ¡lisis de calidad del cÃ³digo

#### **8. ğŸ“Š AnÃ¡lisis de Rendimiento**
- MediciÃ³n de tiempo de respuesta
- Velocidad de generaciÃ³n (tokens/segundo)
- Uso de memoria en tiempo real

#### **9. âš™ï¸ Configuraciones de GeneraciÃ³n**
- **Conservadora**: Respuestas predecibles
- **Balanceada**: Equilibrio creatividad/coherencia
- **Creativa**: MÃ¡xima diversidad
- **DeterminÃ­stica**: Resultados reproducibles

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### **ğŸ“‹ Requisitos:**

```bash
# Dependencias principales
pip install torch transformers accelerate
pip install bitsandbytes  # Para cuantizaciÃ³n
pip install psutil matplotlib  # Para anÃ¡lisis
```

### **ğŸ”‘ ConfiguraciÃ³n de Acceso:**

#### **OpciÃ³n 1: Token HuggingFace (Recomendado)**
```python
# Crear archivo config/hf_config.py
HF_TOKEN = "hf_tu_token_aqui"
```

#### **OpciÃ³n 2: Login Manual**
```bash
huggingface-cli login
```

### **ğŸš€ EjecuciÃ³n:**

#### **En Jupyter/Colab:**
1. Sube el notebook `laboratorio-modulo-n2.ipynb`
2. Ejecuta las celdas secuencialmente
3. InteractÃºa con las demostraciones

#### **En Kaggle:**
1. Activa GPU T4 x2 en configuraciÃ³n
2. Configura HF_TOKEN en Secrets
3. Ejecuta el notebook completo

## ğŸ” AnÃ¡lisis Detallado de Capacidades

### **ğŸ’¬ Capacidades Conversacionales**

**Formato de entrada:**
```python
conversacion = [
    {"role": "system", "content": "Eres un asistente Ãºtil..."},
    {"role": "user", "content": "Â¿Puedes explicar...?"},
    {"role": "assistant", "content": "Por supuesto..."}
]
```

**CaracterÃ­sticas evaluadas:**
- Coherencia en conversaciones largas
- Mantenimiento de contexto
- Personalidad consistente

### **ğŸŒ EvaluaciÃ³n MultilingÃ¼e**

**Idiomas probados:**
- **ğŸ‡ªğŸ‡¸ EspaÃ±ol**: Idioma nativo del curso
- **ğŸ‡ºğŸ‡¸ English**: Idioma principal del modelo
- **ğŸ‡«ğŸ‡· FranÃ§ais**: EvaluaciÃ³n europea
- **ğŸ‡©ğŸ‡ª Deutsch**: Complejidad gramatical
- **ğŸ‡®ğŸ‡¹ Italiano**: Similitud con espaÃ±ol
- **ğŸ‡§ğŸ‡· PortuguÃªs**: Idioma hermano

**MÃ©tricas evaluadas:**
- Fluidez y naturalidad
- PrecisiÃ³n gramatical
- Coherencia semÃ¡ntica

### **ğŸ’» Capacidades de CÃ³digo**

**Lenguajes evaluados:**
- **Python**: Algoritmos y estructuras de datos
- **JavaScript**: ProgramaciÃ³n web y clases
- **SQL**: Consultas y optimizaciÃ³n
- **Algoritmos**: BÃºsqueda, ordenamiento, recursiÃ³n

**Criterios de evaluaciÃ³n:**
- Sintaxis correcta
- LÃ³gica funcional
- Buenas prÃ¡cticas
- Comentarios explicativos

## ğŸ“Š MÃ©tricas de Rendimiento

### **â±ï¸ Tiempo de Respuesta**
- **Promedio**: 0.3-2.0 segundos
- **Factores**: Longitud del prompt, configuraciÃ³n GPU
- **OptimizaciÃ³n**: CuantizaciÃ³n reduce tiempo

### **ğŸš€ Velocidad de GeneraciÃ³n**
- **Rango tÃ­pico**: 10-50 tokens/segundo
- **Dependencias**: Hardware, configuraciÃ³n
- **MediciÃ³n**: Palabras generadas por segundo

### **ğŸ’¾ Uso de Memoria**
- **Modelo completo**: ~15-30 GB
- **Con cuantizaciÃ³n 4-bit**: ~4-8 GB
- **OptimizaciÃ³n**: 60-75% reducciÃ³n

## âš™ï¸ Configuraciones de GeneraciÃ³n

### **ğŸ›ï¸ ParÃ¡metros Clave:**

| **ConfiguraciÃ³n** | **Temperature** | **Top-p** | **Uso Recomendado** |
|-------------------|-----------------|-----------|---------------------|
| **Conservadora** | 0.3 | 0.8 | Respuestas tÃ©cnicas, documentaciÃ³n |
| **Balanceada** | 0.7 | 0.9 | Uso general, conversaciones |
| **Creativa** | 1.0 | 0.95 | Escritura creativa, brainstorming |
| **DeterminÃ­stica** | 0.0 | - | Resultados reproducibles |

### **ğŸ¯ Casos de Uso:**

- **ğŸ“š EducaciÃ³n**: ConfiguraciÃ³n conservadora
- **ğŸ’¬ Chat**: ConfiguraciÃ³n balanceada  
- **ğŸ¨ Creatividad**: ConfiguraciÃ³n creativa
- **ğŸ”¬ InvestigaciÃ³n**: ConfiguraciÃ³n determinÃ­stica

## ğŸš¨ SoluciÃ³n de Problemas

### **âŒ "Modelo no accesible"**
**Problema**: Error 401 al acceder a Llama 3.1
**SoluciÃ³n**:
1. Solicita acceso en [HuggingFace](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct)
2. Configura token HF correctamente
3. El notebook usa modelo alternativo automÃ¡ticamente

### **âŒ "Memoria insuficiente"**
**Problema**: CUDA out of memory
**SoluciÃ³n**:
1. Activa cuantizaciÃ³n 4-bit
2. Reduce batch size
3. Usa modelo mÃ¡s pequeÃ±o

### **âŒ "Respuestas de baja calidad"**
**Problema**: Modelo alternativo genera respuestas pobres
**SoluciÃ³n**:
1. ObtÃ©n acceso a Llama 3.1 original
2. Ajusta parÃ¡metros de generaciÃ³n
3. Usa prompts mÃ¡s especÃ­ficos

## ğŸ“ Ejercicios Sugeridos

### **Nivel BÃ¡sico:**
1. Ejecuta todas las demostraciones del laboratorio
2. Compara respuestas entre configuraciones
3. Prueba prompts en diferentes idiomas

### **Nivel Intermedio:**
1. Modifica parÃ¡metros de generaciÃ³n
2. Crea tus propios prompts de prueba
3. Analiza mÃ©tricas de rendimiento

### **Nivel Avanzado:**
1. Implementa nuevas mÃ©tricas de evaluaciÃ³n
2. Compara con otros modelos
3. Optimiza configuraciones para casos especÃ­ficos

## ğŸ”— Recursos Adicionales

### **ğŸ“š DocumentaciÃ³n Oficial:**
- [Llama 3.1 Model Card](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct)
- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [BitsAndBytesConfig](https://huggingface.co/docs/transformers/quantization)

### **ğŸ¥ Videos Relacionados:**
- [Meta AI: Introducing Llama 3.1](https://ai.meta.com/blog/meta-llama-3-1/)
- [Quantization Techniques](https://huggingface.co/blog/4bit-transformers-bitsandbytes)

### **ğŸ› ï¸ Herramientas Ãštiles:**
- [Gradio](https://gradio.app/) - Interfaces web para modelos
- [Streamlit](https://streamlit.io/) - Apps de ML interactivas
- [LangChain](https://langchain.com/) - Framework para LLMs

## ğŸš€ PrÃ³ximos Pasos

DespuÃ©s de completar este mÃ³dulo:

1. **MÃ³dulo 3**: Fine-tuning y personalizaciÃ³n de modelos
2. **MÃ³dulo 4**: Aplicaciones prÃ¡cticas y casos de uso
3. **MÃ³dulo 5**: Despliegue y optimizaciÃ³n en producciÃ³n

## ğŸ¤ Contribuciones

Â¿Tienes ideas para mejorar el laboratorio?

1. Reporta bugs o problemas
2. Sugiere nuevas demostraciones
3. Comparte tus experimentos
4. Contribuye con optimizaciones

## ğŸ“„ Licencia

Este material educativo estÃ¡ disponible bajo licencia MIT. Libre uso para educaciÃ³n y investigaciÃ³n.

---

**Â¡Explora el poder de Llama 3.1 y descubre las capacidades de los LLMs modernos!** ğŸ¦™ğŸš€âœ¨
